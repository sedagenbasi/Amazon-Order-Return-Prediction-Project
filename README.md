# ğŸ“¦ Amazon SipariÅŸ Ä°ade Tahminlemesi ve Analizi

Bu proje, Amazon sipariÅŸ verilerini kullanarak bir Ã¼rÃ¼nÃ¼n iade edilip edilmeyeceÄŸini sipariÅŸ anÄ±nda tahmin eden bir Makine Ã–ÄŸrenmesi projesidir. 
Ã‡alÄ±ÅŸmada Dengesiz Veri (Imbalanced Data) problemi Ã¼zerinde durulmuÅŸ, Undersampling tekniÄŸi ve XGBoost algoritmasÄ± kullanÄ±larak iade yakalama baÅŸarÄ±sÄ± optimize edilmiÅŸtir.

## ğŸ¯ Projenin AmacÄ±
E-ticaret operasyonlarÄ±nda iadeler, lojistik maliyetlerini artÄ±ran ve kÃ¢rlÄ±lÄ±ÄŸÄ± dÃ¼ÅŸÃ¼ren en bÃ¼yÃ¼k risklerden biridir.
Problem: Veri setindeki sipariÅŸlerin %96'sÄ± baÅŸarÄ±lÄ± teslimat, sadece %3.92'si iadedir. 
Standart modeller bu dengesizlik nedeniyle iadeleri tahmin edememektedir (Accuracy Paradox).
Hedef: Genel doÄŸruluktan (Accuracy) ziyade, Ä°ade Yakalama BaÅŸarÄ±sÄ±nÄ± (Recall) maksimize ederek proaktif Ã¶nlem alÄ±nmasÄ±nÄ± saÄŸlamak.

## ğŸ“Š Veri Seti ve Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering)
* **Veri Seti:** Amazon satÄ±ÅŸ verileri (SipariÅŸ tarihi, tutarÄ±, kargo maliyeti, Ã¼rÃ¼n kategorisi, lokasyon vb.)
* **Veri Boyutu:** ~77.000 SatÄ±r
* **Hedef DeÄŸiÅŸken:** IsReturned (1: Ä°ade, 0: Teslim)
* **TÃ¼retilen Ã–zellikler:**
ShippingRatio: Kargo maliyetinin toplam sipariÅŸ tutarÄ±na oranÄ± hesaplanarak, mÃ¼ÅŸterinin "maliyet hassasiyeti" modele kazandÄ±rÄ±lmÄ±ÅŸtÄ±r.
Month & DayOfWeek: SipariÅŸ tarihinden ay ve gÃ¼n bilgisi tÃ¼retilerek mevsimsellik etkisi yakalanmÄ±ÅŸtÄ±r.

## âš™ï¸ KullanÄ±lan YÃ¶ntemler
Bu projede veri sÄ±zÄ±ntÄ±sÄ±nÄ± Ã¶nlemek ve model baÅŸarÄ±sÄ±nÄ± artÄ±rmak iÃ§in ÅŸu adÄ±mlar izlenmiÅŸtir:
  1. **Veri Ã–n Ä°ÅŸleme:** Eksik verilerin yÃ¶netimi, Label Encoding ve Stratified Train-Test Split (%70-%30).
  2. **Dengesiz Veri Ã‡Ã¶zÃ¼mÃ¼:** RandomUnderSampler kullanÄ±larak sadece eÄŸitim seti 1:1 oranÄ±nda dengelenmiÅŸtir (Majority Class azaltÄ±lmÄ±ÅŸtÄ±r).
  3. **Modeller:** Random Forest: Baseline (Baz) model olarak kullanÄ±ldÄ±.
                   XGBoost: Challenger (Rakip) model olarak kullanÄ±ldÄ± ve optimize edildi.

## ğŸš€ SonuÃ§lar ve KarÅŸÄ±laÅŸtÄ±rma     
YapÄ±lan testler sonucunda XGBoost algoritmasÄ±, Random Forest'a gÃ¶re daha yÃ¼ksek baÅŸarÄ± gÃ¶stermiÅŸtir.

<img width="768" height="287" alt="image" src="https://github.com/user-attachments/assets/fcb610c1-763f-49c8-a23a-2ab0b22fdb2c" />
Not: EÄŸitim seti dengelendiÄŸi iÃ§in modelin genel doÄŸruluÄŸu (Accuracy) dÃ¼ÅŸmÃ¼ÅŸtÃ¼r. Ancak bu bilinÃ§li bir "Trade-off"tur. Bu sayede ham veriyle %0 olan iade yakalama oranÄ± %53'e Ã§Ä±karÄ±lmÄ±ÅŸtÄ±r.

<img width="626" height="470" alt="image" src="https://github.com/user-attachments/assets/d3966c5d-509b-4a47-a4bb-41043dac0ca6" />
<img width="894" height="513" alt="image" src="https://github.com/user-attachments/assets/f489c0ee-6b67-47b2-9697-c02a0189734b" />



